##HMM

paper：[A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition](http://arxiv.org/abs/1603.04713)

### Markov chain

马尔科夫链是只有状态转移（没有提到观察值）。

考虑一个系统描述成在任意时间处于N个状态（$S_1, S_2, ..., S_N$)之一，如下图所示：

![1568773754574](..\images\1568773754574.png)

我们使用$t$表示时间点，我们标识在时间点$t$的实际状态为$q_t$，一阶的马尔科夫链假设时间点$t$的状态只依赖上个时间点$t-1$，即：
$$
P[q_t=S_j|q_{t-1}=S_i, q_{t-2}=S_k,...]=P[q_t=S_j|q_{t-1}=S_i]
$$
上面这个随机过程也可以被称作为显示马尔科夫模型（observable Markov Model），因为这个过程的输出就是在每个时间点的一系列状态，每一个状态对应实际的物理事件。

### Hidden Markov Model

隐形马尔科夫模型（HMM）相比显示的马尔科夫模型，HMM的每个状态对应的是一个概率分布，这个概率分布描述了Observation的各种情况下出现的概率情况。HMM可以看做是一个嵌套的随机过程，在状态随机转移的这个随机过程中嵌套了Observation的随机过程。

HMM的几个要素如下：

- $N$：表示的是模型状态的数量，即$S$的数量，标识状态为$S=\{S_1, S_2, ..., S_N\}$；
- $M$：表示的是观测值的数量，即observation的数量，标识观测结果为$V=\{v_1, v_2, ..., v_M\}$；
- $A$：表示状态转移矩阵，标识为$A=\{a_{ij}\}$，而$a_{ij} = P(q_{t+1}=S_j|q_{t}=S_i)$，就是在当前时间点状态为$S_i$，而下一个时间点状态为$S_j$的概率；
- $B$：各个状态的观测值的分布，标识为$B=\{b_j(k)\}，1\le j\le N$，而$b_j(k)=P(v_k \text { at time t}|q_t=S_j)$，其中$1\le k\le M$；
- $\pi$：表示的是初始状态，标识为$\pi = \{\pi_i\}，1\le i\le N$，其中$\pi_i = P(q_1 = S_i)$；

给定$N,M,A,B,\pi$，就可以生成一大串$O=O_1,O_2...O_T$，其中$O_i\in M$

一般使用简写$\lambda=(A,B,\pi)$来表示隐形马尔科夫模型。

使用HMM解决的问题可以分为三类：

- 问题1：给定$观测序列O和模型\lambda$，求$P(O|\lambda)$，即给定模型和观测序列，求观测序列出现的概率；
- 问题2：给定$观测序列O  和模型\lambda$，求$Q=q_1,..,q_T$，即给定模型和观测序列，什么样的状态序列（$Q$）可以最好的解释这种观测序列，一般就是找最优的状态序列；
- 问题3：给定$观测序列O$，我们如何调整模型$\lambda$的参数，使得$P(O|\lambda)$的值最大，这其实就是在训练模型，在给定一个观测序列，构建一个最好的模型来拟合现实情况中的观测值。

### 三个问题的解决方法

#### 问题1

对于第一个问题的解决方法，最容易想到的就是直接算，但是复杂度是：
$$
O(2T\times N^T)（(2T-1)N^T次乘法，(N^T-1)次加法
$$
所以需要考虑更加可行的方法，这个方法就是forward-backward procedure。有点类似神经网络里面的前馈和反向传递，而问题1只用使用这个方法中的forward procedure，backward procedure用来处理问题三。

算法步骤：

<img src="..\images\1568777682066.png" alt="1568777682066" style="zoom:80%"/><img src="..\images\1568777845684.png" alt="1568777845684" style="zoom:80%;" />

右边图的下面这幅图就很容易让人联想到神经网络结构了。

forward相比之前的笨办法，其实就是原来的方法所有方法都是从头开始计算，而这些从头开始计算的方法有很多计算都是重复的，例如：A方法前T-1次选择的状态都是一样的，只有最后一次不一样，如果是笨办法其实就是都从头计算，而上面的办法是只需要计算最后一次差异即可。

forward和backward都是这个思路，神经网络的反向传递方法也是这个思路来减少计算量，所有梯度计算只计算一次（相同路径）。

forward variable：
$$
\alpha_t(i) = P(O_1O_2...O_t,q_t=S_i|\lambda)
$$
backward variable:
$$
\beta_t(i) = P(O_{t+1}O_{t+2}...O_T|q_t=S_i,\lambda)
$$

#### 问题2

问题2和问题1不同的是，问题2没有明确的解，是求一个最优解。理解应该类似损失函数只有最优解逼近。而且状态之间是独立的，所以我们可以求单个时间点的状态最优。

定义变量$\gamma_t(i)$表示在时间点$t$状态为$S_i$的概率：
$$
\gamma_t(i) = P(q_t=S_i|O,\lambda)=\frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)}\\
q_t=\arg\max_{1\le i\le N}[\gamma_t(i)],1\le t\le T
$$
因为这里求的是每个时间点的最优值，没有考虑序列出现的概率情况，所以有可能序列中两个相邻的状态之间的状态转换概率为0。

一个解决方案是，可以考虑修改最优化目标，例如最大化$q_t$改为最大化$(q_t, q_{t+1})$或三元组$(q_t, q_{t+1}, q_{t+2})$，使用最广泛的还是优化一个最好的状态序列，即最大化$P(Q|O,\lambda)$，这个等价于最大化$P(Q,O|\lambda)$，一个发现这种最优状态序列的方法是维特比算法。

> **维特比算法**
>
> 为了找到给定表现序列$O=\{O_1, O_2,...,O_T\}$的最优的状态序列$Q = \{q_1,q_2,...,q_T\}$，我们定义：
> $$
> \delta_t(i) = \max_{p_1,p_2,...,p_{t-1}}P(q_1,q_2,...,q_t=i,O_1,O_2,...,O_t|\lambda)
> $$
> 我们就定义截止到时间$t$，最终状态为$S_i$，最能得到输出序列的隐藏序列，而下一时刻的各个状态计算值为：
> $$
> \delta_{t+1}(j) = [\max_i(\delta_t(i)\alpha_{ij})]\times b_j(O_{t+1})
> $$
> 使用$\psi$来记录每一次选择的状态，所以整个维特比的算法如下：
>
> 1. 首先初始化计算，计算N次：
>    $$
>    \delta_1(i) = \pi_i\times b_i(O_{t+1})\\
>    \psi_1(i) = 0, 下标表示t=1,i表示下一个状态为S_i的最佳前一个状态
>    $$
>
> 2. 循环计算：
>
> $$
> \delta_t(j) = [\max_{1\le i\le N}(\delta_{t-1}(i)a_{ij})]\times b_j(O_t)\\
> \psi_t(j) = \arg\max_{1\le i\le N}[\delta_{t-1}(i)a_{ij}]\\
> 2\le t\le T， 1\le j\le N
> $$
>
> 3. 计算终止：
>
> $$
> p^* = \max_{1\le i\le N}(\delta_T(i))\\
> q^*_T = \arg\max_{1\le i\le N}[\delta_T(i)]
> $$
>
> 4. 最终结果：
>    $$
>    q_t^* = \psi_{t+1}(q^*_{t+1}),t=T-1,T-2,...,1
>    $$



